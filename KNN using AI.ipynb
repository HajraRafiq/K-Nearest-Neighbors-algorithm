{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b590e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal-length  sepal-width  petal-length  petal-width           Class\n",
      "1             5.1          3.5           1.4          0.2     Iris-setosa\n",
      "2             4.9          3.0           1.4          0.2     Iris-setosa\n",
      "3             4.7          3.2           1.3          0.2     Iris-setosa\n",
      "4             4.6          3.1           1.5          0.2     Iris-setosa\n",
      "5             5.0          3.6           1.4          0.2     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "146           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "147           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "148           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "149           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "150           5.9          3.0           5.1          1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "Confusion Matrix:\n",
      "[[22  0  0]\n",
      " [ 0 18  4]\n",
      " [ 0  1 15]]\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        22\n",
      "Iris-versicolor       0.95      0.82      0.88        22\n",
      " Iris-virginica       0.79      0.94      0.86        16\n",
      "\n",
      "       accuracy                           0.92        60\n",
      "      macro avg       0.91      0.92      0.91        60\n",
      "   weighted avg       0.92      0.92      0.92        60\n",
      "\n",
      "Accuracy: 0.9166666666666666\n",
      "['Iris-versicolor' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-virginica']\n",
      "train: [[-0.80418274 -0.8083591   0.0245335   0.18798613]\n",
      " [-0.32880378 -1.26164458  0.0245335  -0.19653095]\n",
      " [-1.39840644  0.32485459 -1.44747645 -1.35008221]\n",
      " [ 0.5031094  -0.58171636  0.70392271  0.31615849]\n",
      " [-0.0911143  -0.58171636  0.70392271  1.46970974]\n",
      " [ 0.26541992 -0.58171636  0.47745964 -0.06835859]\n",
      " [-0.92302748  1.68471103 -1.33424491 -1.22190984]\n",
      " [ 0.97848836 -0.12843089  0.76053847  1.34153738]\n",
      " [ 0.38426466  0.77814007  0.87377001  1.34153738]\n",
      " [ 1.69155679 -0.35507362  1.38331191  0.70067558]\n",
      " [-0.44764852 -1.48828732 -0.03208227 -0.19653095]\n",
      " [ 0.97848836 -1.26164458  1.10023308  0.70067558]\n",
      " [-0.0911143   2.1379965  -1.50409221 -1.35008221]\n",
      " [ 0.62195414  0.32485459  0.3642281   0.31615849]\n",
      " [ 1.0973331  -0.58171636  0.5340754   0.18798613]\n",
      " [ 0.62195414 -0.35507362  0.25099657  0.05981377]\n",
      " [-1.16071696  0.09821185 -1.33424491 -1.47825457]\n",
      " [ 1.57271205  0.32485459  1.21346461  0.70067558]\n",
      " [ 0.97848836 -0.12843089  0.64730694  0.57250321]\n",
      " [-0.0911143  -0.8083591   0.0245335  -0.06835859]\n",
      " [ 0.5031094   0.55149733  0.47745964  0.44433085]\n",
      " [-1.04187222  1.00478281 -1.27762915 -0.83739276]\n",
      " [-0.20995904 -1.03500184 -0.20192957 -0.32470332]\n",
      " [-1.04187222 -1.71493006 -0.3151611  -0.32470332]\n",
      " [-1.04187222  0.77814007 -1.33424491 -1.35008221]\n",
      " [-1.39840644  0.32485459 -1.27762915 -1.35008221]\n",
      " [-0.20995904  3.04456746 -1.33424491 -1.09373748]\n",
      " [-1.16071696 -1.26164458  0.3642281   0.57250321]\n",
      " [ 0.74079888 -0.12843089  0.76053847  0.9570203 ]\n",
      " [ 0.38426466 -0.58171636  0.5340754   0.70067558]\n",
      " [-1.2795617   0.09821185 -1.27762915 -1.35008221]\n",
      " [-1.04187222  0.55149733 -1.39086068 -1.35008221]\n",
      " [ 0.74079888 -0.12843089  0.93038577  0.70067558]\n",
      " [ 0.14657518 -0.35507362  0.3642281   0.31615849]\n",
      " [-0.685338    1.45806829 -1.33424491 -1.35008221]\n",
      " [-0.92302748  1.68471103 -1.10778184 -1.09373748]\n",
      " [-0.32880378 -0.58171636  0.59069117  0.9570203 ]\n",
      " [ 2.16693575  1.68471103  1.60977498  1.21336502]\n",
      " [ 0.14657518 -0.12843089  0.5340754   0.70067558]\n",
      " [ 1.33502257  0.32485459  0.47745964  0.18798613]\n",
      " [-0.44764852 -1.03500184  0.30761233 -0.06835859]\n",
      " [ 0.97848836  0.09821185  0.98700154  1.46970974]\n",
      " [ 1.45386731 -0.12843089  1.15684884  1.08519266]\n",
      " [-0.44764852 -1.26164458  0.08114927  0.05981377]\n",
      " [-1.75494065  0.32485459 -1.44747645 -1.35008221]], test: [[-1.04187222  0.32485459 -1.50409221 -1.35008221]\n",
      " [ 0.85964362 -0.35507362  0.42084387  0.05981377]\n",
      " [-0.44764852 -1.48828732 -0.08869804 -0.32470332]\n",
      " [-0.0911143  -1.03500184  0.08114927 -0.06835859]\n",
      " [ 0.14657518  0.77814007  0.3642281   0.44433085]\n",
      " [-0.92302748  1.00478281 -1.39086068 -1.35008221]\n",
      " [ 0.97848836  0.55149733  1.04361731  1.5978821 ]\n",
      " [-1.04187222 -0.12843089 -1.27762915 -1.35008221]\n",
      " [ 0.02773044  0.32485459  0.5340754   0.70067558]\n",
      " [-1.87378539 -0.12843089 -1.56070798 -1.47825457]\n",
      " [ 1.21617784  0.09821185  0.59069117  0.31615849]\n",
      " [ 0.02773044 -0.12843089  0.70392271  0.70067558]\n",
      " [ 0.5031094  -0.35507362  0.98700154  0.70067558]\n",
      " [-0.0911143  -0.8083591   0.70392271  0.82884794]\n",
      " [ 1.21617784  0.09821185  0.70392271  1.34153738]\n",
      " [ 0.5031094   0.55149733  1.21346461  1.5978821 ]\n",
      " [ 0.97848836  0.55149733  1.04361731  1.08519266]\n",
      " [-1.16071696 -0.12843089 -1.39086068 -1.35008221]\n",
      " [-0.80418274  2.36463924 -1.33424491 -1.47825457]\n",
      " [ 0.74079888  0.32485459  0.70392271  0.9570203 ]\n",
      " [ 0.97848836  0.09821185  0.47745964  0.31615849]\n",
      " [-1.04187222 -2.39485827 -0.20192957 -0.32470332]\n",
      " [-0.92302748  0.55149733 -1.22101338 -0.96556512]\n",
      " [-0.92302748  1.45806829 -1.33424491 -1.09373748]\n",
      " [ 2.16693575 -1.03500184  1.72300651  1.34153738]\n",
      " [ 1.81040153 -0.58171636  1.27008038  0.82884794]\n",
      " [-0.92302748  1.68471103 -1.27762915 -1.35008221]\n",
      " [-1.04187222  1.23142555 -1.39086068 -1.35008221]\n",
      " [-1.2795617  -0.12843089 -1.39086068 -1.47825457]\n",
      " [-1.16071696  0.09821185 -1.33424491 -1.47825457]\n",
      " [ 0.62195414 -0.58171636  0.98700154  1.21336502]\n",
      " [-0.44764852  1.00478281 -1.44747645 -1.35008221]\n",
      " [ 0.5031094  -1.26164458  0.64730694  0.82884794]\n",
      " [ 2.16693575 -0.58171636  1.60977498  0.9570203 ]\n",
      " [-0.32880378 -0.8083591   0.1943808   0.05981377]\n",
      " [-1.2795617   0.77814007 -1.27762915 -1.35008221]\n",
      " [-0.44764852 -1.71493006  0.08114927  0.05981377]\n",
      " [ 0.26541992 -0.12843089  0.59069117  0.70067558]\n",
      " [-0.20995904 -1.26164458  0.64730694  0.9570203 ]\n",
      " [ 1.57271205  1.23142555  1.27008038  1.5978821 ]\n",
      " [-0.92302748 -1.26164458 -0.48500841 -0.19653095]\n",
      " [-0.20995904  1.68471103 -1.22101338 -1.22190984]\n",
      " [ 2.04809101 -0.12843089  1.55315921  1.08519266]\n",
      " [-1.16071696 -1.48828732 -0.3151611  -0.32470332]\n",
      " [ 0.5031094   0.77814007  0.98700154  1.46970974]]\n",
      "train: [[-1.04187222  0.32485459 -1.50409221 -1.35008221]\n",
      " [ 0.85964362 -0.35507362  0.42084387  0.05981377]\n",
      " [-0.44764852 -1.48828732 -0.08869804 -0.32470332]\n",
      " [-0.0911143  -1.03500184  0.08114927 -0.06835859]\n",
      " [ 0.14657518  0.77814007  0.3642281   0.44433085]\n",
      " [-0.92302748  1.00478281 -1.39086068 -1.35008221]\n",
      " [ 0.97848836  0.55149733  1.04361731  1.5978821 ]\n",
      " [-1.04187222 -0.12843089 -1.27762915 -1.35008221]\n",
      " [ 0.02773044  0.32485459  0.5340754   0.70067558]\n",
      " [-1.87378539 -0.12843089 -1.56070798 -1.47825457]\n",
      " [ 1.21617784  0.09821185  0.59069117  0.31615849]\n",
      " [ 0.02773044 -0.12843089  0.70392271  0.70067558]\n",
      " [ 0.5031094  -0.35507362  0.98700154  0.70067558]\n",
      " [-0.0911143  -0.8083591   0.70392271  0.82884794]\n",
      " [ 1.21617784  0.09821185  0.70392271  1.34153738]\n",
      " [ 0.5031094   0.55149733  1.21346461  1.5978821 ]\n",
      " [ 0.97848836  0.55149733  1.04361731  1.08519266]\n",
      " [-1.16071696 -0.12843089 -1.39086068 -1.35008221]\n",
      " [-0.80418274  2.36463924 -1.33424491 -1.47825457]\n",
      " [ 0.74079888  0.32485459  0.70392271  0.9570203 ]\n",
      " [ 0.97848836  0.09821185  0.47745964  0.31615849]\n",
      " [-1.04187222 -2.39485827 -0.20192957 -0.32470332]\n",
      " [-0.92302748  0.55149733 -1.22101338 -0.96556512]\n",
      " [-0.92302748  1.45806829 -1.33424491 -1.09373748]\n",
      " [ 2.16693575 -1.03500184  1.72300651  1.34153738]\n",
      " [ 1.81040153 -0.58171636  1.27008038  0.82884794]\n",
      " [-0.92302748  1.68471103 -1.27762915 -1.35008221]\n",
      " [-1.04187222  1.23142555 -1.39086068 -1.35008221]\n",
      " [-1.2795617  -0.12843089 -1.39086068 -1.47825457]\n",
      " [-1.16071696  0.09821185 -1.33424491 -1.47825457]\n",
      " [ 0.62195414 -0.58171636  0.98700154  1.21336502]\n",
      " [-0.44764852  1.00478281 -1.44747645 -1.35008221]\n",
      " [ 0.5031094  -1.26164458  0.64730694  0.82884794]\n",
      " [ 2.16693575 -0.58171636  1.60977498  0.9570203 ]\n",
      " [-0.32880378 -0.8083591   0.1943808   0.05981377]\n",
      " [-1.2795617   0.77814007 -1.27762915 -1.35008221]\n",
      " [-0.44764852 -1.71493006  0.08114927  0.05981377]\n",
      " [ 0.26541992 -0.12843089  0.59069117  0.70067558]\n",
      " [-0.20995904 -1.26164458  0.64730694  0.9570203 ]\n",
      " [ 1.57271205  1.23142555  1.27008038  1.5978821 ]\n",
      " [-0.92302748 -1.26164458 -0.48500841 -0.19653095]\n",
      " [-0.20995904  1.68471103 -1.22101338 -1.22190984]\n",
      " [ 2.04809101 -0.12843089  1.55315921  1.08519266]\n",
      " [-1.16071696 -1.48828732 -0.3151611  -0.32470332]\n",
      " [ 0.5031094   0.77814007  0.98700154  1.46970974]], test: [[-0.80418274 -0.8083591   0.0245335   0.18798613]\n",
      " [-0.32880378 -1.26164458  0.0245335  -0.19653095]\n",
      " [-1.39840644  0.32485459 -1.44747645 -1.35008221]\n",
      " [ 0.5031094  -0.58171636  0.70392271  0.31615849]\n",
      " [-0.0911143  -0.58171636  0.70392271  1.46970974]\n",
      " [ 0.26541992 -0.58171636  0.47745964 -0.06835859]\n",
      " [-0.92302748  1.68471103 -1.33424491 -1.22190984]\n",
      " [ 0.97848836 -0.12843089  0.76053847  1.34153738]\n",
      " [ 0.38426466  0.77814007  0.87377001  1.34153738]\n",
      " [ 1.69155679 -0.35507362  1.38331191  0.70067558]\n",
      " [-0.44764852 -1.48828732 -0.03208227 -0.19653095]\n",
      " [ 0.97848836 -1.26164458  1.10023308  0.70067558]\n",
      " [-0.0911143   2.1379965  -1.50409221 -1.35008221]\n",
      " [ 0.62195414  0.32485459  0.3642281   0.31615849]\n",
      " [ 1.0973331  -0.58171636  0.5340754   0.18798613]\n",
      " [ 0.62195414 -0.35507362  0.25099657  0.05981377]\n",
      " [-1.16071696  0.09821185 -1.33424491 -1.47825457]\n",
      " [ 1.57271205  0.32485459  1.21346461  0.70067558]\n",
      " [ 0.97848836 -0.12843089  0.64730694  0.57250321]\n",
      " [-0.0911143  -0.8083591   0.0245335  -0.06835859]\n",
      " [ 0.5031094   0.55149733  0.47745964  0.44433085]\n",
      " [-1.04187222  1.00478281 -1.27762915 -0.83739276]\n",
      " [-0.20995904 -1.03500184 -0.20192957 -0.32470332]\n",
      " [-1.04187222 -1.71493006 -0.3151611  -0.32470332]\n",
      " [-1.04187222  0.77814007 -1.33424491 -1.35008221]\n",
      " [-1.39840644  0.32485459 -1.27762915 -1.35008221]\n",
      " [-0.20995904  3.04456746 -1.33424491 -1.09373748]\n",
      " [-1.16071696 -1.26164458  0.3642281   0.57250321]\n",
      " [ 0.74079888 -0.12843089  0.76053847  0.9570203 ]\n",
      " [ 0.38426466 -0.58171636  0.5340754   0.70067558]\n",
      " [-1.2795617   0.09821185 -1.27762915 -1.35008221]\n",
      " [-1.04187222  0.55149733 -1.39086068 -1.35008221]\n",
      " [ 0.74079888 -0.12843089  0.93038577  0.70067558]\n",
      " [ 0.14657518 -0.35507362  0.3642281   0.31615849]\n",
      " [-0.685338    1.45806829 -1.33424491 -1.35008221]\n",
      " [-0.92302748  1.68471103 -1.10778184 -1.09373748]\n",
      " [-0.32880378 -0.58171636  0.59069117  0.9570203 ]\n",
      " [ 2.16693575  1.68471103  1.60977498  1.21336502]\n",
      " [ 0.14657518 -0.12843089  0.5340754   0.70067558]\n",
      " [ 1.33502257  0.32485459  0.47745964  0.18798613]\n",
      " [-0.44764852 -1.03500184  0.30761233 -0.06835859]\n",
      " [ 0.97848836  0.09821185  0.98700154  1.46970974]\n",
      " [ 1.45386731 -0.12843089  1.15684884  1.08519266]\n",
      " [-0.44764852 -1.26164458  0.08114927  0.05981377]\n",
      " [-1.75494065  0.32485459 -1.44747645 -1.35008221]]\n",
      "Confusion Matrix:\n",
      "[[22  0  0]\n",
      " [ 0 18  4]\n",
      " [ 0  1 15]]\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        22\n",
      "Iris-versicolor       0.95      0.82      0.88        22\n",
      " Iris-virginica       0.79      0.94      0.86        16\n",
      "\n",
      "       accuracy                           0.92        60\n",
      "      macro avg       0.91      0.92      0.91        60\n",
      "   weighted avg       0.92      0.92      0.92        60\n",
      "\n",
      "Accuracy: 0.9166666666666666\n",
      "Confusion Matrix:\n",
      "[[22  0  0]\n",
      " [ 0 18  4]\n",
      " [ 0  1 15]]\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        22\n",
      "Iris-versicolor       0.95      0.82      0.88        22\n",
      " Iris-virginica       0.79      0.94      0.86        16\n",
      "\n",
      "       accuracy                           0.92        60\n",
      "      macro avg       0.91      0.92      0.91        60\n",
      "   weighted avg       0.92      0.92      0.92        60\n",
      "\n",
      "Accuracy: 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hajra\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, scipy, numpy as np\n",
    "import sklearn.preprocessing\n",
    "\n",
    "\n",
    "# ### Loading the iris dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "headernames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class'] #Assigning the headers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ds = pd.read_csv('iris.csv', names = headernames)\n",
    "ds.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(ds)\n",
    "\n",
    "\n",
    "# ### Splitting up in feature attributes and class variable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#x = ds.iloc[:, :-1].values \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y=ds.iloc[:, 4].values\n",
    "\n",
    "\n",
    "# ### Train and Test Split\n",
    "# Next, we will divide the data into train and test split. Following code will split the dataset into 60% training data and 40% of testing data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.40)\n",
    "\n",
    "\n",
    "# ### Data Scaling using the StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# ### Training a KNN Classifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 7)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# ### Making the Predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "# ### Output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)\n",
    "result2 = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy:\",result2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y_pred = classifier.predict(X_test)\n",
    "print(Y_pred)\n",
    "\n",
    "\n",
    "# ### K-fold Crossvalidation\n",
    "# K-Folds cross-validator provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds (without shuffling by default). Each fold is then used once as a validation while the k - 1 remaining folds form the training set.\n",
    "# \n",
    "# more information on https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "# prepare cross validation\n",
    "kfold = KFold(2, True) # value of K and shuffle? \n",
    "# enumerate splits\n",
    "for train, test in kfold.split(X_train):\n",
    "    print('train: %s, test: %s' % (X_train[train], X_train[test]))\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for train, test in kfold.split(X_train):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    result = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(result)\n",
    "    result1 = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\",)\n",
    "    print (result1)\n",
    "    result2 = accuracy_score(y_test,y_pred)\n",
    "    print(\"Accuracy:\",result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd6a303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
